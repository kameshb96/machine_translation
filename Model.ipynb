{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline with attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDzKxfsx6K3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-nlp\n",
        "import torch\n",
        "from torchnlp import metrics\n",
        "from torch import nn\n",
        "from torchtext import datasets\n",
        "from torchtext import data\n",
        "from torchtext.vocab import Vectors\n",
        "from google.colab import drive\n",
        "from torch import optim\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "path = '/content/drive/My Drive/MT Project/' #Path to general folder\n",
        "\n",
        "#General params\n",
        "batch_size = 32 #Batch size\n",
        "epochs = 15 #How many epochs we train\n",
        "learning_rate = 0.01\n",
        "layers = 6 #Num of layers in the encoder and decoder\n",
        "hidden_size = 1000 #Hiddensize dimension\n",
        "dropout = 0.1 #0 equals no dropout\n",
        "val_every = 3 #Performs validation after this many epochs, 0 is only at last epoch\n",
        "\n",
        "only_val = False #Indicates if we only evaluate an already trained model\n",
        "\n",
        "save_model = True\n",
        "load_model = True\n",
        "load_path = 0 #0 is auto select latest, else specify\n",
        "\n",
        "save_path = path+'save/'\n",
        "val_file = path+'val_files/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD3T0d5J6qsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preload the GloVe embeddings\n",
        "vectors_de = Vectors(name='vectors_de.txt', cache=path)\n",
        "vectors_en = Vectors(name='vectors_en.txt', cache=path)\n",
        "\n",
        "#Build the vocabs and iterators\n",
        "src = data.Field(init_token='<bos>', eos_token='<eos>', lower=True, sequential=True)\n",
        "trg = data.Field(init_token='<bos>', eos_token='<eos>', lower=True, sequential=True)\n",
        "mt_train = datasets.TranslationDataset(\n",
        "    path=path + 'dev', exts=('.de', '.en'),\n",
        "    fields=(src, trg))\n",
        "\n",
        "mt_dev = datasets.TranslationDataset(\n",
        "    path=path + 'dev', exts=('.de', '.en'),\n",
        "    fields=(src, trg))\n",
        "\n",
        "src.build_vocab(mt_train, min_freq=2, vectors=vectors_de) #198491\n",
        "trg.build_vocab(mt_train, min_freq=2, vectors=vectors_en) #123156\n",
        "\n",
        "train_iter = data.BucketIterator(\n",
        "    dataset=mt_train, batch_size=batch_size,\n",
        "    sort_key=lambda x: data.interleave_keys(len(x.src), len(x.trg)))\n",
        "\n",
        "val_iter = data.BucketIterator(dataset=mt_dev, batch_size=1, train=False)\n",
        "\n",
        "#Build the two embedding layers\n",
        "embed_src = torch.nn.Embedding(len(src.vocab), 300)\n",
        "embed_trg = torch.nn.Embedding(len(trg.vocab), 300)\n",
        "\n",
        "embed_src.weight.data.copy_(src.vocab.vectors)\n",
        "embed_trg.weight.data.copy_(trg.vocab.vectors)\n",
        "\n",
        "#We fix these weights, they are not updated during training\n",
        "embed_src.weight.requires_grad = False\n",
        "embed_trg.weight.requires_grad = False\n",
        "\n",
        "#Auto selects 'functions'\n",
        "if load_path == 0 and load_model == True:\n",
        "  models = os.listdir(save_path)\n",
        "  models.sort()\n",
        "  load_path = save_path + models[-1]\n",
        "\n",
        "if val_every == 0:\n",
        "  val_every = epochs+5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmL7myYbQ8o6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, h_size, emb_size, dropout):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden = h_size\n",
        "    self.lstm = nn.LSTM(emb_size, h_size, batch_first=True, bidirectional=False,\n",
        "                       num_layers=layers, dropout=dropout)\n",
        "     \n",
        "  def forward(self, inp, hidden, cell_state):\n",
        "    #Default encoder structure\n",
        "    output_enc, (hidden_enc, cell_state_enc) = self.lstm(inp, (hidden, cell_state))\n",
        "    return output_enc, (hidden_enc, cell_state_enc)\n",
        "  \n",
        "  def initHidden(self, size=batch_size):\n",
        "    #Resets the hidden states and cell states between different sentences\n",
        "    return (torch.zeros(layers, size, self.hidden, device=device), #Initial hidden states\n",
        "              torch.zeros(layers, size, self.hidden, device=device)) #(all zeros)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4myG-Ym3RH_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, h_size, emb_size, output_size, layers, dropout):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = h_size\n",
        "    self.output_dim = output_size\n",
        "    self.layers = layers\n",
        "    self.lstm = nn.LSTM(emb_size, self.hidden_size, batch_first=True, \n",
        "                        num_layers=layers, dropout=dropout)\n",
        "    self.linear_1 = nn.Linear(h_size, 10*h_size)\n",
        "    self.linear_out = nn.Linear(10*h_size, output_size)\n",
        "    self.softmax = torch.nn.Softmax(dim=1)\n",
        "  \n",
        "  def forward(self, enc_states, inp, hidden, cell_state, att_mask, cov):\n",
        "    #Our decoder with attention and coverage\n",
        "    #Two linear layers at the end\n",
        "    output_dec, (hidden_dec, cell_state_dec) = self.lstm(inp, (hidden, cell_state))\n",
        "    \n",
        "    attn = hidden_dec[-1,:]\n",
        "    attn = attn.unsqueeze(1)\n",
        "    attn = attn.expand_as(enc_states)\n",
        "    attn = torch.sum(attn*enc_states, dim=-1).squeeze(-1)\n",
        "    attn_dist = self.softmax(attn - att_mask*10**16)\n",
        "    cov_loss = torch.sum(torch.min(cov.to('cpu'), attn_dist.to('cpu')))\n",
        "    cov = cov + attn_dist.to('cpu')\n",
        "    attn_dist = attn_dist.unsqueeze(-1)\n",
        "    attn_dist = attn_dist.expand_as(enc_states)\n",
        "    context = attn_dist*enc_states\n",
        "    context = torch.sum(context,dim=1)\n",
        "    context = torch.cat((context, hidden_dec[-1,:]), dim=-1)\n",
        "    scores = self.linear_1(hidden_dec[-1,:,:])\n",
        "    scores = self.linear_out(scores).unsqueeze(1)\n",
        "    return scores, cov, cov_loss, (hidden_dec, cell_state_dec)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CERvoXjA0EdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_loop(lr, epochs, train_iter, val_iter, criterion, enc, dec, save, load, val_file, only_val=False, val_every=val_every):   \n",
        "  #Only optimize non embedding params\n",
        "  optim_enc = optim.Adam([param for param in enc.parameters() if param.requires_grad == True], lr = lr, weight_decay=0.0001)\n",
        "  optim_dec = optim.Adam([param for param in dec.parameters() if param.requires_grad == True], lr = lr, weight_decay=0.0001)\n",
        "  if load == True:\n",
        "    #Loader function for presaved weights\n",
        "    try:\n",
        "      checkpoint = torch.load(load_path)\n",
        "      load_epoch = checkpoint['epoch']\n",
        "      train_loss = checkpoint['train_loss']\n",
        "      enc.load_state_dict(checkpoint['enc_state_dict'])\n",
        "      optim_enc.load_state_dict(checkpoint['enc_optimizer_state_dict'])\n",
        "      dec.load_state_dict(checkpoint['dec_state_dict'])\n",
        "      optim_dec.load_state_dict(checkpoint['dec_optimizer_state_dict'])\n",
        "      print('Model loaded succesfully')\n",
        "      plt.plot(train_loss)\n",
        "      plt.title('Training loss this far')\n",
        "      plt.show()\n",
        "    except:\n",
        "      #No model loaded error\n",
        "      raise Exception(('No model found at: '+load_path))    \n",
        "  else:\n",
        "      #If we start from scratch\n",
        "      train_loss = []\n",
        "      load_epoch = 0\n",
        "      \n",
        "  if only_val == False:\n",
        "    #If we intent to train and not just validate\n",
        "    for epoch in range(epochs-load_epoch):\n",
        "      epoch = epoch + load_epoch\n",
        "      train_iter.init_epoch()\n",
        "      train_loss_ = 0\n",
        "      i = 0\n",
        "      if epoch == 4:\n",
        "        #Large step size first 4 epochs then we slow it down\n",
        "        optim_enc = optim.Adam([param for param in enc.parameters() if param.requires_grad == True], lr = 0.1*lr, weight_decay=0.0001)\n",
        "        optim_dec = optim.Adam([param for param in dec.parameters() if param.requires_grad == True], lr = 0.1*lr, weight_decay=0.0001)\n",
        "      for data in train_iter:\n",
        "        optim_enc.zero_grad()\n",
        "        optim_dec.zero_grad()\n",
        "        x = data.src.transpose(1,0)\n",
        "        batch_size = data.batch_size\n",
        "        y = data.trg.transpose(1,0)\n",
        "        #Coverage place holder\n",
        "        cov = torch.zeros(x.size())\n",
        "        cov=torch.zeros(1).to(device); att_mask = torch.zeros(1).to(device)\n",
        "        #Invert input sentence\n",
        "        x = torch.flip(x, [1])\n",
        "        #Attention mask\n",
        "        att_mask = torch.where(x == src.vocab.stoi['<pad>'], torch.ones(1), torch.zeros(1))\n",
        "        att_mask = att_mask.to(device)\n",
        "        x_emb = embed_src(x).to(device)\n",
        "        #Placeholder for scores\n",
        "        scores = torch.zeros((batch_size, y.size()[1], len(trg.vocab))).to(device)\n",
        "        #Beam place holders\n",
        "        beam_score = torch.zeros((batch_size, beam_size, y.size()[1]))\n",
        "        bi_candidates = torch.zeros((batch_size, beam_size**2))\n",
        "        bs_candidates = torch.zeros((batch_size, beam_size**2))\n",
        "        beam_hidden = torch.zeros((beam_size, batch_size, num_layers, hidden_size))\n",
        "        beam_cell = torch.zeros((beam_size, batch_size, num_layers, hidden_size))\n",
        "        scores_list = torch.zeros((beam_size, batch_size, y.size()[1]))\n",
        "        best_k = torch.zeros(y.size()[1])\n",
        "        for j in range(y.size()[1]):\n",
        "            if j == 0:\n",
        "              (hidden, cell_state) = enc.initHidden(size=batch_size)\n",
        "              enc_states, (hidden, cell_state) = enc(x_emb, hidden, cell_state)\n",
        "              y_hat = torch.zeros((batch_size, y.size()[1], beam_size)).long()\n",
        "              y_hat[:,j,:] = trg.vocab.stoi['<bos>']\n",
        "              y_hat_emb = embed_trg(y_hat[:,j,0].to('cpu')).to(device).unsqueeze(1)\n",
        "              score, (hidden, cell_state) = dec(enc_states, y_hat_emb, hidden, cell_state, att_mask)\n",
        "              scores_list[:,:,0] = score[:, 0, y[j]] #Score is: batch x 1 x vocab_size\n",
        "              #Pick the beam_size best candidates\n",
        "              beam_score[:,:,j], _ = torch.topk(score, beam_size)   \n",
        "              #Save the hidden states corresponding to them (same here when j = 0)\n",
        "              beam_hidden = hidden.unsqueeze(0).expand((beam_size, batch_size, num_layers, hidden_size))\n",
        "              beam_cell = cell_state.unsqueeze(0).expand((beam_size, batch_size, num_layers, hidden_size))\n",
        "              idx = torch.arange(0,beam_size, 1)\n",
        "            else:\n",
        "              for k in range(beam_size):\n",
        "                #Embed y\n",
        "                y_hat_emb = embed_trg(y_hat[:,j,k].to('cpu')).to(device).unsqueeze(1)\n",
        "                #Run decoder step\n",
        "                score, (hidden, cell_state) = dec(enc_states, y_hat_emb, beam_hidden[idx[k]], beam_cell[idx[k]], att_mask)\n",
        "                #Get beam size best candidates from this beam (beam k)\n",
        "                scores_list[k,:,0] = score[:, 0, y[j]] #Score is: batch x 1 x vocab_size\n",
        "                bs_candidates[:, k*beam_size:(1+k)*beam_size] , bi_candidates[:, k*beam_size:(1+k)*beam_size] = torch.topk(score, beam_size)\n",
        "                #Save their hidden and cell states\n",
        "                beam_hidden[k,:,:,:] = hidden\n",
        "                beam_cell[k,:,:,:] = cell_state\n",
        "              #Find the beam size best candidates from the k beams\n",
        "              beam_score[:,:,j], temp_idx = torch.topk(bs_candidates, beam_size) \n",
        "              for i1 in range(batch_size): #i1 is batch looper\n",
        "                for i2 in range(beam_size): #i2 is beam looper\n",
        "                  y_hat[i1, j+1, i2] = torch.argmax(beam_score[i1, i2])\n",
        "              idx = temp_idx // beam_size\n",
        "              best_k[j] = idx[0] #Highest scored candidate in the beam\n",
        "        y = y.to(device)\n",
        "        for i1 in batch_size:\n",
        "          pred = []\n",
        "          corr = []\n",
        "          for j in range(y.size()[1]):\n",
        "            pred.append(trg.vocab.itos[y_hat[i1, j, best_k[j]]])\n",
        "            corr.append(trg.vocab.itos[y[i1, j]])\n",
        "            loss = metrics.get_moses_multi_bleu([' '.join(pred[:-1])], [' '.join(correct[1:])])\n",
        "            loss = loss * 1-scores_list[best_k[j], i1, j] + beam_score[i1, best_k[j], j]\n",
        "        #We add loss and cov_loss, we multiply by 15 so they have the ratio we want (about 1/3 of loss in first few epochs is from coverage)\n",
        "        loss = loss + cov_loss*15\n",
        "        loss.backward()\n",
        "        optim_enc.step()\n",
        "        optim_dec.step()\n",
        "        train_loss_ = train_loss_ + loss.item() / (len(train_iter)*batch_size)\n",
        "        \n",
        "        i += 1\n",
        "        if i % 2000 == 0:\n",
        "          #This is just so we know the model isent frozen :p\n",
        "          print(str(i) + ' / ' + str(len(train_iter)))\n",
        "\n",
        "      train_loss.append(train_loss_)\n",
        "      \n",
        "      #Plot the training losses\n",
        "      plt.close()\n",
        "      plt.plot(train_loss)\n",
        "      plt.title('Train loss: %.4f' % train_loss_)\n",
        "      plt.show()\n",
        "      \n",
        "      #Save model after every epoch\n",
        "      if save == True:\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'enc_state_dict': enc.state_dict(),\n",
        "            'enc_optimizer_state_dict': optim_enc.state_dict(),\n",
        "            'dec_state_dict': dec.state_dict(),\n",
        "            'dec_optimizer_state_dict': optim_dec.state_dict(),\n",
        "            'train_loss': train_loss}, \n",
        "            save_path+str(epoch+1).zfill(3) + '.pt')\n",
        "        print('Model saved')\n",
        "      \n",
        "      #Validate at speficied epochs\n",
        "      if ((epoch+1) % val_every == 0):\n",
        "        enc.eval()\n",
        "        dec.eval()\n",
        "        val_loop(val_iter, enc, dec, val_file, epoch+1, full_val=True)\n",
        "        enc.train()\n",
        "        dec.train()\n",
        "      #Always validate at last epoch\n",
        "      elif (epoch+1 == epochs):\n",
        "        enc.eval()\n",
        "        dec.eval()\n",
        "        val_loop(val_iter, enc, dec, val_file, epoch+1, full_val=True)\n",
        "    print(train_loss)\n",
        "  \n",
        "  #If we only wish to validate\n",
        "  if only_val == True:\n",
        "    enc.eval()\n",
        "    dec.eval()\n",
        "    epoch = load_epoch\n",
        "    val_loop(val_iter, enc, dec, val_file, epoch+1, full_val=True)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LhkxMpcvhQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_loop(val_iter, enc, dec, val_file_path, epoch, full_val=False):\n",
        "  val_iter.init_epoch()\n",
        "  i = 0\n",
        "  #Place holder for validations stats\n",
        "  bleu_score = 0\n",
        "  bleu_error = 0\n",
        "  for data in val_iter:\n",
        "    i += 1\n",
        "    if full_val == False:\n",
        "      #This can be used to see that the model actually learns without running full val\n",
        "      if i % 50 == 0:\n",
        "        break\n",
        "    j = 0\n",
        "    #As before, flip x, make att mask etc\n",
        "    x = data.src.transpose(1,0)\n",
        "    batch_size = data.batch_size\n",
        "    y = data.trg.transpose(1,0)\n",
        "    #Coverage place holder\n",
        "    cov = torch.zeros(x.size())\n",
        "    cov=torch.zeros(1).to(device); att_mask = torch.zeros(1).to(device)\n",
        "    #Invert input sentence\n",
        "    x = torch.flip(x, [1])\n",
        "    #Attention mask\n",
        "    att_mask = torch.where(x == src.vocab.stoi['<pad>'], torch.ones(1), torch.zeros(1))\n",
        "    att_mask = att_mask.to(device)\n",
        "    x_emb = embed_src(x).to(device)\n",
        "    #Placeholder for scores\n",
        "    scores = torch.zeros((batch_size, y.size()[1], len(trg.vocab))).to(device)\n",
        "    #Beam place holders\n",
        "    beam_score = torch.zeros((batch_size, beam_size, y.size()[1]))\n",
        "    bi_candidates = torch.zeros((batch_size, beam_size**2))\n",
        "    bs_candidates = torch.zeros((batch_size, beam_size**2))\n",
        "    beam_hidden = torch.zeros((beam_size, batch_size, num_layers, hidden_size))\n",
        "    beam_cell = torch.zeros((beam_size, batch_size, num_layers, hidden_size))\n",
        "    scores_list = torch.zeros((beam_size, batch_size, y.size()[1]))\n",
        "    best_k = torch.zeros(y.size()[1])\n",
        "    \n",
        "    #Write the validations to a file\n",
        "    val_file = open(val_file_path + str(epoch).zfill(3)+'.txt', 'a')\n",
        "    correct_file = open(val_file_path + str(epoch).zfill(3)+'_correct.txt','a')\n",
        "    cont = True\n",
        "    pred = []; correct = []\n",
        "    \n",
        "    while cont:\n",
        "        \n",
        "        if j == 0:\n",
        "          (hidden, cell_state) = enc.initHidden(size=batch_size)\n",
        "          enc_states, (hidden, cell_state) = enc(x_emb, hidden, cell_state)\n",
        "          y_hat = torch.zeros((batch_size, y.size()[1], beam_size)).long()\n",
        "          y_hat[:,j,:] = trg.vocab.stoi['<bos>']\n",
        "          y_hat_emb = embed_trg(y_hat[:,j,0].to('cpu')).to(device).unsqueeze(1)\n",
        "          score, (hidden, cell_state) = dec(enc_states, y_hat_emb, hidden, cell_state, att_mask)\n",
        "          scores_list[:,:,0] = score[:, 0, y[j]] #Score is: batch x 1 x vocab_size\n",
        "          #Pick the beam_size best candidates\n",
        "          beam_score[:,:,j], _ = torch.topk(score, beam_size)   \n",
        "          #Save the hidden states corresponding to them (same here when j = 0)\n",
        "          beam_hidden = hidden.unsqueeze(0).expand((beam_size, batch_size, num_layers, hidden_size))\n",
        "          beam_cell = cell_state.unsqueeze(0).expand((beam_size, batch_size, num_layers, hidden_size))\n",
        "          idx = torch.arange(0,beam_size, 1)\n",
        "        else:\n",
        "          for k in range(beam_size):\n",
        "            #Embed y\n",
        "            y_hat_emb = embed_trg(y_hat[:,j,k].to('cpu')).to(device).unsqueeze(1)\n",
        "            #Run decoder step\n",
        "            score, (hidden, cell_state) = dec(enc_states, y_hat_emb, beam_hidden[idx[k]], beam_cell[idx[k]], att_mask)\n",
        "            #Get beam size best candidates from this beam (beam k)\n",
        "            scores_list[k,:,0] = score[:, 0, y[j]] #Score is: batch x 1 x vocab_size\n",
        "            bs_candidates[:, k*beam_size:(1+k)*beam_size] , bi_candidates[:, k*beam_size:(1+k)*beam_size] = torch.topk(score, beam_size)\n",
        "            #Save their hidden and cell states\n",
        "            beam_hidden[k,:,:,:] = hidden\n",
        "            beam_cell[k,:,:,:] = cell_state\n",
        "          #Find the beam size best candidates from the k beams\n",
        "          beam_score[:,:,j], temp_idx = torch.topk(bs_candidates, beam_size) \n",
        "          for i1 in range(batch_size): #i1 is batch looper\n",
        "            for i2 in range(beam_size): #i2 is beam looper\n",
        "              y_hat[i1, j+1, i2] = torch.argmax(beam_score[i1, i2])\n",
        "          idx = temp_idx // beam_size\n",
        "          best_k[j] = idx[0] #Highest scored candidate in the beam\n",
        "    y = y.to(device)\n",
        "    for i1 in batch_size:\n",
        "      pred = []\n",
        "      corr = []\n",
        "      for j in range(y.size()[1]):\n",
        "        pred.append(trg.vocab.itos[y_hat[i1, j, best_k[j]]])\n",
        "        corr.append(trg.vocab.itos[y[i1, j]])\n",
        "\n",
        "      if (idx == trg.vocab.stoi['<eos>']) or (i > 100):\n",
        "        cont = False\n",
        "        try:\n",
        "          bleu_score += metrics.get_moses_multi_bleu([' '.join(pred)], [' '.join(correct[1:])]) / len(val_iter)\n",
        "        except:\n",
        "          bleu_error += 1\n",
        "        pred.append('\\n')\n",
        "        correct.append('\\n')\n",
        "        val_file.write(' '.join(pred))\n",
        "        correct_file.write(' '.join(correct))\n",
        "      j += 1\n",
        "    if full_val == False:\n",
        "      print(correct)\n",
        "      print(pred)\n",
        "  \n",
        "  print('Average BLEU score for this validation pass: %.4f' % (bleu_score))\n",
        "  print('%.0f sentences where not scored duo to error' %(bleu_error))\n",
        "  \n",
        "  val_file.close()\n",
        "  correct_file.close()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XGeZvW17c9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Runs the model\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=trg.vocab.stoi['<pad>']) \n",
        "enc = Encoder(hidden_size, 300, dropout).to(device)\n",
        "dec = Decoder(hidden_size, 300, len(trg.vocab), layers, dropout).to(device)\n",
        "train_loop(learning_rate, epochs, train_iter, val_iter, criterion, enc, dec, save_model, load_model, val_file, only_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}